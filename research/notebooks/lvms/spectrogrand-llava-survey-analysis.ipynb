{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7773126,"sourceType":"datasetVersion","datasetId":4547642},{"sourceId":7892190,"sourceType":"datasetVersion","datasetId":4633707}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nall_image_files = []\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        _f = (os.path.join(dirname, filename))\n        if \".jpeg\" in _f:\n            all_image_files.append(_f)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T10:05:24.967017Z","iopub.execute_input":"2024-04-28T10:05:24.967860Z","iopub.status.idle":"2024-04-28T10:05:25.872039Z","shell.execute_reply.started":"2024-04-28T10:05:24.967826Z","shell.execute_reply":"2024-04-28T10:05:25.871030Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install dependencies\nSource: https://huggingface.co/llava-hf/vip-llava-7b-hf","metadata":{}},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers.git\n!pip install -q bitsandbytes==0.41.3 accelerate==0.25.0","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:05:36.633692Z","iopub.execute_input":"2024-04-28T10:05:36.634155Z","iopub.status.idle":"2024-04-28T10:06:43.243677Z","shell.execute_reply.started":"2024-04-28T10:05:36.634127Z","shell.execute_reply":"2024-04-28T10:06:43.242455Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load quantised model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:06:56.101738Z","iopub.execute_input":"2024-04-28T10:06:56.102698Z","iopub.status.idle":"2024-04-28T10:06:56.108787Z","shell.execute_reply.started":"2024-04-28T10:06:56.102664Z","shell.execute_reply":"2024-04-28T10:06:56.107790Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nmodel_id = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n\npipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:06:57.231170Z","iopub.execute_input":"2024-04-28T10:06:57.231994Z","iopub.status.idle":"2024-04-28T10:09:18.234812Z","shell.execute_reply.started":"2024-04-28T10:06:57.231942Z","shell.execute_reply":"2024-04-28T10:09:18.233808Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-04-28 10:06:58.951575: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 10:06:58.951705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 10:06:59.088057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f60497cb7645e3b63b717b5b8fecdf"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9842fac5471745099f4615eacfd61382"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76e1c5ccd2614404aeea1a1a24e32f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66af428b999249c6b9327d8a96dfe677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820f9472bfd3441d8c795a0b9626904f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f5b998793847b5ba05ab5a249aa3c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f37da81190a443fbafb5974f43ee4fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3e959528a14ec48a56000347862ea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19d4b4a96734f9bbebabb242e1aef91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1451331e464d9caf4a9c165e8874a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae712a51edd3422cbf5224c8768f4623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92e8f21978444b89b2f14dfcf342f63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ade89c59e7b46819dd9d4e66fd595e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d350eb9c3534390ace673ffb7c4425f"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/754 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0924ec1d31d4402da34081e788382a2e"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Prompt","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nbase_prompt = \"Creativity has multiple definitions, but broadly, it revolves around novelty (something you haven't seen before), value (relevant to the task at hand), and surprisingness (it should not be something you'd conventionally expect). Pleaes score the creativity between 0 to 100 of this album cover created for the theme of <THEME>. For this task, you have the ability to perceive visual content. Please output only a single number between 0 and 100 without any further comments about the image or the theme.\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:09:29.760137Z","iopub.execute_input":"2024-04-28T10:09:29.761392Z","iopub.status.idle":"2024-04-28T10:09:29.766073Z","shell.execute_reply.started":"2024-04-28T10:09:29.761354Z","shell.execute_reply":"2024-04-28T10:09:29.765068Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nall_llava_outputs = []\n\nTHEME_DICT = {\n    'car' : 'fast car',\n    'dog' : 'dog in space',\n    'matrix' : 'the matrix',\n    'robots' : 'robots',\n    'space' : 'space explorer'\n}\n\nfor _f in tqdm(all_image_files):\n    img = Image.open(_f)\n    selected_theme = _f.split(\"/\")[-1].replace(\".jpeg\", \"\")\n    selected_prompt = base_prompt.replace(\"<THEME>\", THEME_DICT[selected_theme])\n    \n    llava_prompt = f\"[INST] <image>\\n{selected_prompt} [/INST]\"\n    \n    outputs = pipe(img, prompt=llava_prompt, generate_kwargs={\"max_new_tokens\": 200})\n    generated_score = (outputs[0][\"generated_text\"])\n    all_llava_outputs.append(generated_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:09:32.592400Z","iopub.execute_input":"2024-04-28T10:09:32.593020Z","iopub.status.idle":"2024-04-28T10:10:43.062974Z","shell.execute_reply.started":"2024-04-28T10:09:32.592977Z","shell.execute_reply":"2024-04-28T10:10:43.062036Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 10/10 [01:10<00:00,  7.05s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame({\n    \"file_name\" : all_image_files,\n    \"llava_outputs\" : all_llava_outputs\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:11:09.656842Z","iopub.execute_input":"2024-04-28T10:11:09.657248Z","iopub.status.idle":"2024-04-28T10:11:09.670049Z","shell.execute_reply.started":"2024-04-28T10:11:09.657220Z","shell.execute_reply":"2024-04-28T10:11:09.669154Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['llava_score'] = df['llava_outputs'].apply(lambda x: float(x.split('[/INST]')[1].strip())/100.0)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:11:11.032645Z","iopub.execute_input":"2024-04-28T10:11:11.033052Z","iopub.status.idle":"2024-04-28T10:11:11.048605Z","shell.execute_reply.started":"2024-04-28T10:11:11.033014Z","shell.execute_reply":"2024-04-28T10:11:11.047659Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:11:11.992103Z","iopub.execute_input":"2024-04-28T10:11:11.992477Z","iopub.status.idle":"2024-04-28T10:11:12.009853Z","shell.execute_reply.started":"2024-04-28T10:11:11.992446Z","shell.execute_reply":"2024-04-28T10:11:12.008887Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                           file_name  \\\n0  /kaggle/input/spectrogrand-survey-images/spect...   \n1  /kaggle/input/spectrogrand-survey-images/spect...   \n2  /kaggle/input/spectrogrand-survey-images/spect...   \n3  /kaggle/input/spectrogrand-survey-images/spect...   \n4  /kaggle/input/spectrogrand-survey-images/spect...   \n\n                                       llava_outputs  llava_score  \n0  [INST]  \\nCreativity has multiple definitions,...          0.8  \n1  [INST]  \\nCreativity has multiple definitions,...          0.8  \n2  [INST]  \\nCreativity has multiple definitions,...          0.8  \n3  [INST]  \\nCreativity has multiple definitions,...          0.8  \n4  [INST]  \\nCreativity has multiple definitions,...          0.8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>llava_outputs</th>\n      <th>llava_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/spectrogrand-survey-images/spect...</td>\n      <td>[INST]  \\nCreativity has multiple definitions,...</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/spectrogrand-survey-images/spect...</td>\n      <td>[INST]  \\nCreativity has multiple definitions,...</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/spectrogrand-survey-images/spect...</td>\n      <td>[INST]  \\nCreativity has multiple definitions,...</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/spectrogrand-survey-images/spect...</td>\n      <td>[INST]  \\nCreativity has multiple definitions,...</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/spectrogrand-survey-images/spect...</td>\n      <td>[INST]  \\nCreativity has multiple definitions,...</td>\n      <td>0.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv(\"spectrogrand_survey_llava_outputs_v2.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:11:23.351515Z","iopub.execute_input":"2024-04-28T10:11:23.352366Z","iopub.status.idle":"2024-04-28T10:11:23.358111Z","shell.execute_reply.started":"2024-04-28T10:11:23.352333Z","shell.execute_reply":"2024-04-28T10:11:23.357048Z"},"trusted":true},"execution_count":12,"outputs":[]}]}
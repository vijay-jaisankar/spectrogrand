{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7773126,"sourceType":"datasetVersion","datasetId":4547642},{"sourceId":8251645,"sourceType":"datasetVersion","datasetId":4895116}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Dependencies","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install --upgrade -qr /kaggle/input/spectrogrand-public-release/kaggle-public-release/REQUIREMENTS.txt\n!pip install -q essentia-tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:06:25.136858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load models","metadata":{}},{"cell_type":"code","source":"!wget \"https://essentia.upf.edu/models/classification-heads/danceability/danceability-discogs-effnet-1.pb\"\n!wget \"https://essentia.upf.edu/models/feature-extractors/discogs-effnet/discogs-effnet-bs64-1.pb\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import AudioLDM2Pipeline\nfrom typing import Optional, List\nimport scipy\nimport numpy as np\nimport librosa\nimport pickle\nfrom essentia.standard import MonoLoader, TensorflowPredictMusiCNN, TensorflowPredict2D\nfrom essentia.standard import MonoLoader, TensorflowPredictVGGish, TensorflowPredict2D\nfrom essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D\n\nimport torch\ntorch.random.manual_seed(42)\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nfrom transformers import ClapModel, ClapProcessor\n\n\n# Load the CLAP pipeline\nclap_model = ClapModel.from_pretrained(\"laion/clap-htsat-fused\")\nclap_model.to(DEVICE)\nclap_processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-fused\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:43:26.408228Z","iopub.execute_input":"2024-04-28T09:43:26.408632Z","iopub.status.idle":"2024-04-28T09:43:28.047606Z","shell.execute_reply.started":"2024-04-28T09:43:26.408598Z","shell.execute_reply":"2024-04-28T09:43:28.046787Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Migrate code to compute audio scores","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    @method resample_audio_data\n        Resample audio data to a target sampling rate\n    @param origin_data: Numpy array containing the audio data (@note Intended inputs stem from the `load_wav_file` method)\n    @param origin_sampling_rate: Sampling rate of the input audio (@note Intended inputs stem from the `load_wav_file` method)\n    @param new_sampling_rate: Desired sampling rate (default: 48000)\n\"\"\"\ndef resample_audio_data(origin_data:np.ndarray, origin_sampling_rate:int, new_sampling_rate:int=48000) -> Optional[np.ndarray]:\n    try:\n        origin_type = origin_data.dtype\n        resampled_data = librosa.resample(origin_data.T.astype('float'), orig_sr = origin_sampling_rate, target_sr = new_sampling_rate) \n        resampled_data = librosa.to_mono(resampled_data)        \n        resampled_data = resampled_data.T.astype(origin_type)\n        data_np = np.array(resampled_data)\n        return data_np\n    except Exception as e:\n        print(f\"Error while resampling audio data: {e}\")\n        return None\n\n\"\"\"\n    @method load_wav_file\n        Load a wav file from a given path\n    @param input_file_path: Path containing the input audio file\n\"\"\"\ndef load_wav_file(input_file_path:str):\n    try:\n        sr, data = scipy.io.wavfile.read(input_file_path)\n        return sr, data\n    except Exception as e:\n        print(f\"Error while reading {input_file_path}: {e}\")\n        return None, None\n    \n\n\"\"\"\n    @method compute_clap_embeddings\n        Compute CLAP embeddings for an input audio file\n    @input input_file_path: Path to the input audio file\n\"\"\"\ndef compute_clap_embeddings(input_file_path:str) -> Optional[torch.Tensor]:\n    try:\n        global clap_processor, clap_model, DEVICE\n        # Load audio and resample to 48000 Hz\n        sr, origin_data = load_wav_file(input_file_path=input_file_path)\n        origin_data_resampled = resample_audio_data(origin_data=origin_data, origin_sampling_rate=sr, new_sampling_rate=48000)\n        # Get CLAP outputs\n        clap_inputs = clap_processor(audios=origin_data_resampled, sampling_rate=48000, return_tensors=\"pt\").to(DEVICE)\n        clap_outputs = clap_model.get_audio_features(**clap_inputs)\n        audio_embeds = clap_outputs[0].detach().cpu()\n        return audio_embeds\n    except Exception as e:\n        print(f\"Error while computing CLAP embeddings for {input_file_path}: {e}\")\n        return None\n    \n\"\"\"\n    @method compute_clap_similarity\n        Compute CLAP similarity for an input audio file with respect to a saved ground truth mapping of embeddings\n        @input input_file_path: Path to the input audio file\n        @input ground_truth_dict_path: Path to the mapping .pkl file \n        @note The ground truth mapping should be a .pkl file with the following schema:\n            {\n                \"genre_name\" : [list_of_clap_embeddings],\n                ...\n            }\n        @input filter_genre: Genre name to compute from. If values are to be aggregated across the entire search space, this value should be left as `None`. (default: None)\n\"\"\"\ndef compute_clap_similarity(input_file_path:str, ground_truth_dict_path:str, filter_genre:Optional[str]=None) -> Optional[float]:\n    try:\n        # Load the embeddings from the ground truth mapping and set the search space\n        with open(ground_truth_dict_path, \"rb\") as f:\n            data = pickle.load(f)\n        input_search_space_embeds = []\n        if filter_genre is not None:\n            # Convert `filter_genre` into underscore format if required\n            if \"_\" not in filter_genre: # eg: 'bass house'\n                filter_genre = filter_genre.replace(\" \",\"_\")\n            input_search_space_embeds = data[filter_genre]\n        else:\n            for _k in data:\n                input_search_space_embeds.extend(data[_k])\n        assert len(input_search_space_embeds) >= 1\n\n        # Compute CLAP embeddings for the input file\n        source_embed = compute_clap_embeddings(input_file_path=input_file_path)\n\n        # Keep track of running dot product scores\n        running_score = 0.0\n        for target_embed in input_search_space_embeds:\n            z = source_embed@target_embed.T\n            running_score += float(z.detach().cpu())\n\n        # Return the average dot product score\n        return (running_score)/float(len(input_search_space_embeds))\n    except Exception as e:\n        print(f\"Error while computing CLAP similarity score for {input_file_path}: {e}\")\n        return None\n    \n\"\"\"\n    @method get_danceability_score\n        Use Essentia to score an audio track on its danceability\n    @input input_file_path: Path to the input audio file\n    @input embedding_model_path: Path to the essentia encoder model (@note To ensure compatibility, this should be a `.pb` file)\n    @input danceability_model_path: Path to the essentia danceability computation model (@note To ensure compatibility, this should be a `.pb` file)\n\"\"\"\ndef get_danceability_score(input_file_path:str, embedding_model_path:str, danceability_model_path:str) -> Optional[float]:\n    try:\n        # Load audio and get embeddings\n        audio = MonoLoader(filename=input_file_path, sampleRate=16000, resampleQuality=4)()\n        embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=embedding_model_path, output=\"PartitionedCall:1\")\n        embeddings = embedding_model(audio)\n\n        # Load model and get predictions\n        model = TensorflowPredict2D(graphFilename=danceability_model_path, output=\"model/Softmax\")\n        predictions = model(embeddings)\n        mean_danceability_score = np.mean(predictions[:,0])\n        return mean_danceability_score\n    except Exception as e:\n        print(f\"Error while computing danceability score for {input_file_path}: {e}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:43:31.661289Z","iopub.execute_input":"2024-04-28T09:43:31.661683Z","iopub.status.idle":"2024-04-28T09:43:31.680890Z","shell.execute_reply.started":"2024-04-28T09:43:31.661651Z","shell.execute_reply":"2024-04-28T09:43:31.679903Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"GT_EMBEDDINGS_PATH = \"/kaggle/input/spectrogrand-public-release/kaggle-public-release/housex_ground_truth_embeddings.pkl\"\ndef calculate_novelty_score(input_file_path:str) -> float:\n    try:\n        sim_score = compute_clap_similarity(input_file_path=input_file_path, ground_truth_dict_path=GT_EMBEDDINGS_PATH, filter_genre=None)\n        novelty_score = 1.0 - sim_score\n        return novelty_score\n    except Exception as e:\n        print(f\"Error while computing novelty score: {e}\")\n        return -1.0\n    \nESSENTIA_EMBEDDINGS_MODEL_PATH = \"/kaggle/working/discogs-effnet-bs64-1.pb\"\nESSENTIA_DANCEABILITY_MODEL_PATH = \"/kaggle/working/danceability-discogs-effnet-1.pb\"\ndef calculate_danceability_score(input_file_path:str) -> float:\n    try:\n        essentia_score = get_danceability_score(input_file_path=input_file_path, embedding_model_path=ESSENTIA_EMBEDDINGS_MODEL_PATH, danceability_model_path=ESSENTIA_DANCEABILITY_MODEL_PATH)\n        return essentia_score\n    except Exception as e:\n        print(f\"Error while computing danceability score: {e}\")\n        return -1.0\n    \ndef get_music_score(input_file_path:str) -> float:\n    try:\n        value_score = calculate_danceability_score(input_file_path=input_file_path)\n        novelty_score = calculate_novelty_score(input_file_path=input_file_path)\n        if value_score == -1.0 or novelty_score == -1.0:\n            return -1.0\n        # Update the weights if your use case values value more than novelty or vice-versa\n        return 0.50*value_score + 0.50*novelty_score\n    except Exception as e:\n        print(f\"Error while computing audio score: {e}\")\n        return -1.0","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:43:32.713956Z","iopub.execute_input":"2024-04-28T09:43:32.714831Z","iopub.status.idle":"2024-04-28T09:43:32.723631Z","shell.execute_reply.started":"2024-04-28T09:43:32.714795Z","shell.execute_reply":"2024-04-28T09:43:32.722549Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Compute scores for all files in the survey base","metadata":{}},{"cell_type":"code","source":"from glob import glob\nall_file_names = []\nall_scores = []\n\npool_1_files = glob(\"/kaggle/input/spectrogrand-pmqd-survey/selected_audio_files_survey/pool-1/*.wav\")\n\nfor _f in pool_1_files:\n    score = get_music_score(_f)\n    all_file_names.append(_f)\n    all_scores.append(score)\n    \nprint('='*90)\n\npool_2_files = glob(\"/kaggle/input/spectrogrand-pmqd-survey/selected_audio_files_survey/pool-2/*.wav\")\n\nfor _f in pool_2_files:\n    score = get_music_score(_f)\n    all_file_names.append(_f)\n    all_scores.append(score)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:43:50.308901Z","iopub.execute_input":"2024-04-28T09:43:50.310266Z","iopub.status.idle":"2024-04-28T09:44:09.785949Z","shell.execute_reply.started":"2024-04-28T09:43:50.310220Z","shell.execute_reply":"2024-04-28T09:44:09.784838Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n","output_type":"stream"},{"name":"stdout","text":"==========================================================================================\n","output_type":"stream"},{"name":"stderr","text":"[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/discogs-effnet-bs64-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/kaggle/working/danceability-discogs-effnet-1.pb`\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Save scores","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame({\n    \"filename\": all_file_names,\n    \"audio_score\" : all_scores\n})","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:44:14.768686Z","iopub.execute_input":"2024-04-28T09:44:14.769093Z","iopub.status.idle":"2024-04-28T09:44:14.778950Z","shell.execute_reply.started":"2024-04-28T09:44:14.769062Z","shell.execute_reply":"2024-04-28T09:44:14.777922Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:44:17.800795Z","iopub.execute_input":"2024-04-28T09:44:17.801712Z","iopub.status.idle":"2024-04-28T09:44:17.820574Z","shell.execute_reply.started":"2024-04-28T09:44:17.801676Z","shell.execute_reply":"2024-04-28T09:44:17.819763Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                            filename  audio_score\n0  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.537624\n1  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.524891\n2  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.536908\n3  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.342022\n4  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.542865\n5  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.531359\n6  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.538075\n7  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.534503\n8  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.533203\n9  /kaggle/input/spectrogrand-pmqd-survey/selecte...     0.438718","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>audio_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.537624</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.524891</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.536908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.342022</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.542865</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.531359</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.538075</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.534503</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.533203</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>/kaggle/input/spectrogrand-pmqd-survey/selecte...</td>\n      <td>0.438718</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv(\"spectrogrand_audio_survey.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:44:27.908135Z","iopub.execute_input":"2024-04-28T09:44:27.908916Z","iopub.status.idle":"2024-04-28T09:44:27.916363Z","shell.execute_reply.started":"2024-04-28T09:44:27.908883Z","shell.execute_reply":"2024-04-28T09:44:27.915388Z"},"trusted":true},"execution_count":15,"outputs":[]}]}
# Epoch hyperparams
stabilization_epochs: 1.0
pruning_epochs: 7.0
finetuning_epochs: 7.0

# Learning rate hyperparams
init_lr: 0.0004
final_lr: 0.0001

# Pruning hyperparams
init_sparsity: 0.05
final_sparsity: 0.75

# Stabalization Stage
training_modifiers:
  - !EpochRangeModifier
    start_epoch: 0.0
    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)
  
  - !SetLearningRateModifier
    start_epoch: 0.0
    learning_rate: eval(init_lr)

# Pruning Stage
pruning_modifiers:
  - !LearningRateFunctionModifier
    init_lr: eval(init_lr)
    final_lr: eval(final_lr)
    lr_func: cosine
    start_epoch: eval(stabilization_epochs)
    end_epoch: eval(stabilization_epochs + pruning_epochs)
    
  - !GlobalMagnitudePruningModifier
    init_sparsity: eval(init_sparsity)
    final_sparsity: eval(final_sparsity)
    start_epoch: eval(stabilization_epochs)
    end_epoch: eval(stabilization_epochs + pruning_epochs)
    update_frequency: 0.5
    params:        
        - '0.conv1.weight'
        - 're:0.layer1.*.conv1.weight'
        - 're:0.layer1.*.conv2.weight'
        - 're:0.layer1.*.conv3.weight'
        - 're:0.layer1.0.downsample.0.weight'
        - 're:0.layer2.*.conv1.weight'
        - 're:0.layer2.*.conv2.weight'
        - 're:0.layer2.*.conv3.weight'
        - 're:0.layer2.0.downsample.0.weight'
        - 're:0.layer3.*.conv1.weight'
        - 're:0.layer3.*.conv2.weight'
        - 're:0.layer3.*.conv3.weight'
        - 're:0.layer3.0.downsample.0.weight'
        - 're:0.layer4.*.conv1.weight'
        - 're:0.layer4.*.conv2.weight'
        - 're:0.layer4.*.conv3.weight'
        - 're:0.layer4.0.downsample.0.weight'
    leave_enabled: True

# Finetuning Stage
finetuning_modifiers:
  - !LearningRateFunctionModifier
    init_lr: eval(init_lr)
    final_lr: eval(final_lr)
    lr_func: cosine
    start_epoch: eval(stabilization_epochs + pruning_epochs)
    end_epoch: eval(stabilization_epochs + pruning_epochs + finetuning_epochs)

